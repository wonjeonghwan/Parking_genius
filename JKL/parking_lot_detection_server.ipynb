{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. GPU ì‚¬ìš©ì„¤ì •(0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # 1ë²ˆ GPUë§Œ ë…¸ì¶œë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "import ast  # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë“ˆ\n",
    "\n",
    "# ë°ì´í„° í´ë” ê²½ë¡œ\n",
    "dataset_root = \"data\"\n",
    "\n",
    "# Train & Validation JSON ë° ì´ë¯¸ì§€ í´ë” ê²½ë¡œ\n",
    "train_json_folder = os.path.join(dataset_root, \"train/labels\")\n",
    "train_image_folder = os.path.join(dataset_root, \"train/images\")\n",
    "val_json_folder = os.path.join(dataset_root, \"validation/labels\")\n",
    "val_image_folder = os.path.join(dataset_root, \"validation/images\")\n",
    "\n",
    "# YOLO ë³€í™˜ ë°ì´í„° ì €ì¥ í´ë”\n",
    "train_output_labels = os.path.join(dataset_root, \"train/labels\")\n",
    "val_output_labels = os.path.join(dataset_root, \"validation/labels\")\n",
    "\n",
    "# ì €ì¥í•  í´ë” ìƒì„±\n",
    "os.makedirs(train_output_labels, exist_ok=True)\n",
    "os.makedirs(val_output_labels, exist_ok=True)\n",
    "\n",
    "# **í´ë˜ìŠ¤ ìë™ ìˆ˜ì§‘**\n",
    "unique_classes = set()\n",
    "\n",
    "# **JSON íŒŒì¼ì„ í™•ì¸í•˜ì—¬ ëª¨ë“  í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” í•¨ìˆ˜**\n",
    "def collect_classes(json_folder):\n",
    "    json_files = glob.glob(os.path.join(json_folder, \"**\", \"*.json\"), recursive=True)\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        annotations = data.get(\"Learning Data Info\", {}).get(\"annotations\", [])\n",
    "        for annotation in annotations:\n",
    "            class_id = annotation.get(\"class_id\")\n",
    "            unique_classes.add(class_id)  # í´ë˜ìŠ¤ ID ì €ì¥\n",
    "\n",
    "# Train & Validation í´ë”ì—ì„œ í´ë˜ìŠ¤ ìˆ˜ì§‘\n",
    "collect_classes(train_json_folder)\n",
    "collect_classes(val_json_folder)\n",
    "\n",
    "# **ìë™ìœ¼ë¡œ YOLO í´ë˜ìŠ¤ ë§¤í•‘ ìƒì„±**\n",
    "class_mapping = {class_id: idx for idx, class_id in enumerate(sorted(unique_classes))}\n",
    "print(f\"âœ… YOLO í´ë˜ìŠ¤ ë§¤í•‘ ì™„ë£Œ: {class_mapping}\")\n",
    "\n",
    "# **JSONì—ì„œ ì‹¤ì œ ì´ë¯¸ì§€ í¬ê¸°(í•´ìƒë„)ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜**\n",
    "def get_image_size_from_json(json_data):\n",
    "    \"\"\"JSON íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ í•´ìƒë„ë¥¼ ê°€ì ¸ì™€ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    resolution = json_data.get(\"Raw Data Info\", {}).get(\"resolution\", \"3840, 2160\")\n",
    "    try:\n",
    "        width, height = map(int, resolution.split(\", \"))  # \"3840, 2160\" â†’ (3840, 2160)\n",
    "        return width, height\n",
    "    except ValueError:\n",
    "        print(f\"âš ï¸ í•´ìƒë„ ê°’ì´ ì˜ëª»ë¨: {resolution}, ê¸°ë³¸ê°’(3840x2160) ì‚¬ìš©\")\n",
    "        return 3840, 2160  # ê¸°ë³¸ í•´ìƒë„ ë°˜í™˜\n",
    "\n",
    "# **ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜ í•¨ìˆ˜**\n",
    "def parse_bbox(bbox):\n",
    "    \"\"\"ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ê°’ì´ ë¬¸ìì—´ì´ë©´ ë³€í™˜\"\"\"\n",
    "    if isinstance(bbox, str):\n",
    "        try:\n",
    "            bbox = ast.literal_eval(bbox)  # ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "        except (SyntaxError, ValueError):\n",
    "            print(f\"âš ï¸ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨: {bbox}\")\n",
    "            return None\n",
    "    if len(bbox) != 4:\n",
    "        print(f\"âš ï¸ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ê°œìˆ˜ ì˜¤ë¥˜: {bbox}\")\n",
    "        return None\n",
    "    return bbox\n",
    "\n",
    "# JSON íŒŒì¼ì„ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜\n",
    "def convert_json_to_yolo(json_folder, image_folder, output_labels_folder):\n",
    "    json_files = glob.glob(os.path.join(json_folder, \"**\", \"*.json\"), recursive=True)\n",
    "    print(f\"ğŸ” {json_folder} ë‚´ JSON íŒŒì¼ ê°œìˆ˜: {len(json_files)}\")\n",
    "\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            # **JSON íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ì—¬ ì´ë¯¸ì§€ íŒŒì¼ëª… ìƒì„±**\n",
    "            json_filename = os.path.basename(json_file)\n",
    "            image_filename = os.path.splitext(json_filename)[0] + \".jpg\"\n",
    "\n",
    "            txt_file_path = os.path.join(output_labels_folder, os.path.splitext(json_filename)[0] + \".txt\")\n",
    "\n",
    "            # JSONì—ì„œ í•´ìƒë„(ì´ë¯¸ì§€ í¬ê¸°) ê°€ì ¸ì˜¤ê¸°\n",
    "            img_w, img_h = get_image_size_from_json(data)\n",
    "\n",
    "            annotations = data.get(\"Learning Data Info\", {}).get(\"annotations\", [])\n",
    "            yolo_labels = []\n",
    "\n",
    "            for annotation in annotations:\n",
    "                class_id = annotation.get(\"class_id\")\n",
    "                bbox = annotation.get(\"coord\")\n",
    "\n",
    "                if class_id not in class_mapping:\n",
    "                    print(f\"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” í´ë˜ìŠ¤: {class_id}, í•´ë‹¹ ê°ì²´ëŠ” ì œì™¸ë¨.\")\n",
    "                    continue\n",
    "\n",
    "                yolo_class_id = class_mapping[class_id]\n",
    "\n",
    "                # **ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜**\n",
    "                bbox = parse_bbox(bbox)\n",
    "                if bbox is None:\n",
    "                    continue  # ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨í•œ ê²½ìš° í•´ë‹¹ ê°ì²´ ë¬´ì‹œ\n",
    "\n",
    "                x_min, y_min, bbox_w, bbox_h = bbox\n",
    "                center_x = x_min + bbox_w / 2\n",
    "                center_y = y_min + bbox_h / 2\n",
    "\n",
    "                # YOLO ì •ê·œí™” (ê° ì´ë¯¸ì§€ì˜ ì‹¤ì œ í•´ìƒë„ ê¸°ì¤€)\n",
    "                center_x /= img_w\n",
    "                center_y /= img_h\n",
    "                bbox_w /= img_w\n",
    "                bbox_h /= img_h\n",
    "\n",
    "                # **YOLO í˜•ì‹ ë°ì´í„° ì¶”ê°€ (ì£¼ì„ ì œê±°)**\n",
    "                yolo_label = f\"{yolo_class_id} {center_x:.6f} {center_y:.6f} {bbox_w:.6f} {bbox_h:.6f}\"\n",
    "                yolo_labels.append(yolo_label)  # âš ï¸ ì£¼ì„ ì œê±°\n",
    "\n",
    "            with open(txt_file_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_labels))\n",
    "\n",
    "            print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {txt_file_path} (ì´ë¯¸ì§€ í¬ê¸°: {img_w}x{img_h})\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë³€í™˜ ì‹¤íŒ¨: {json_file} - {str(e)}\")\n",
    "\n",
    "# Train & Validation ë°ì´í„° ë³€í™˜ ì‹¤í–‰\n",
    "convert_json_to_yolo(train_json_folder, train_image_folder, train_output_labels)\n",
    "convert_json_to_yolo(val_json_folder, val_image_folder, val_output_labels)\n",
    "\n",
    "print(\"ğŸ¯ ëª¨ë“  JSON íŒŒì¼ì„ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import cv2\n",
    "# import xml.etree.ElementTree as ET\n",
    "# import yaml\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# # def convert_xml_to_yolo(xml_path):\n",
    "# #     \"\"\"\n",
    "# #     pklot í´ë”ì˜ XML annotation íŒŒì¼ì„ YOLO í˜•ì‹ì˜ txt íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "# #     ì£¼ì°¨ ê³µê°„ì˜ occupied ì—¬ë¶€ë¥¼ í´ë˜ìŠ¤(Label)ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "# #     \"\"\"\n",
    "# #     tree = ET.parse(xml_path)\n",
    "# #     root = tree.getroot()\n",
    "    \n",
    "# #     base = os.path.splitext(os.path.basename(xml_path))[0]\n",
    "# #     img_path = os.path.join(os.path.dirname(xml_path), base + \".jpg\")\n",
    "# #     if not os.path.exists(img_path):\n",
    "# #         print(f\"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {img_path}\")\n",
    "# #         return\n",
    "    \n",
    "# #     image = cv2.imread(img_path)\n",
    "# #     if image is None:\n",
    "# #         print(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}\")\n",
    "# #         return\n",
    "# #     img_h, img_w = image.shape[:2]\n",
    "    \n",
    "# #     yolo_lines = []\n",
    "# #     for space in root.findall('space'):\n",
    "# #         occupied_str = space.get('occupied', '0')\n",
    "# #         try:\n",
    "# #             label = int(occupied_str)\n",
    "# #         except ValueError:\n",
    "# #             label = 0\n",
    "        \n",
    "# #         contour = space.find('contour')\n",
    "# #         if contour is None:\n",
    "# #             continue\n",
    "# #         xs, ys = [], []\n",
    "# #         for point in contour.findall('point'):\n",
    "# #             try:\n",
    "# #                 x = float(point.get('x'))\n",
    "# #                 y = float(point.get('y'))\n",
    "# #             except (TypeError, ValueError):\n",
    "# #                 continue\n",
    "# #             xs.append(x)\n",
    "# #             ys.append(y)\n",
    "# #         if not xs or not ys:\n",
    "# #             continue\n",
    "        \n",
    "# #         xmin, xmax = min(xs), max(xs)\n",
    "# #         ymin, ymax = min(ys), max(ys)\n",
    "# #         bbox_w = xmax - xmin\n",
    "# #         bbox_h = ymax - ymin\n",
    "# #         center_x = xmin + bbox_w / 2\n",
    "# #         center_y = ymin + bbox_h / 2\n",
    "        \n",
    "# #         # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "# #         center_x_norm = center_x / img_w\n",
    "# #         center_y_norm = center_y / img_h\n",
    "# #         width_norm = bbox_w / img_w\n",
    "# #         height_norm = bbox_h / img_h\n",
    "        \n",
    "# #         line = f\"{label} {center_x_norm:.6f} {center_y_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
    "# #         yolo_lines.append(line)\n",
    "    \n",
    "# #     txt_path = os.path.join(os.path.dirname(xml_path), base + \".txt\")\n",
    "# #     with open(txt_path, 'w') as f:\n",
    "# #         for line in yolo_lines:\n",
    "# #             f.write(line + \"\\n\")\n",
    "# #     print(f\"YOLO annotation íŒŒì¼ ìƒì„± ì™„ë£Œ: {txt_path}\")\n",
    "\n",
    "# # def create_segmented_labels(folder_path):\n",
    "# #     \"\"\"\n",
    "# #     pklotsegmented í´ë” ë‚´ ëª¨ë“  jpg ì´ë¯¸ì§€ì˜ ìƒìœ„ í´ë”(Empty/Occupied)ë¥¼ ì°¸ê³ í•˜ì—¬\n",
    "# #     YOLO í˜•ì‹ì˜ annotationì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# #     \"\"\"\n",
    "# #     image_files = glob.glob(os.path.join(folder_path, \"**/*.jpg\"), recursive=True)\n",
    "# #     for img_file in image_files:\n",
    "# #         parent_folder = os.path.basename(os.path.dirname(img_file))\n",
    "# #         label = 1 if parent_folder.lower() == \"occupied\" else 0\n",
    "        \n",
    "# #         annotation_line = f\"{label} 0.500000 0.500000 1.000000 1.000000\"\n",
    "# #         txt_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "# #         if not os.path.exists(txt_file):\n",
    "# #             with open(txt_file, 'w') as f:\n",
    "# #                 f.write(annotation_line + \"\\n\")\n",
    "# #             print(f\"Segmented annotation íŒŒì¼ ìƒì„± ì™„ë£Œ: {txt_file}\")\n",
    "\n",
    "# # 1ï¸âƒ£ **1ë‹¨ê³„: ì „ì²´ ì£¼ì°¨ì¥ ì´ë¯¸ì§€ í•™ìŠµ**\n",
    "# pklot_folder = \"PKLot\"\n",
    "# # xml_files = glob.glob(os.path.join(pklot_folder, \"**/**/*.xml\"), recursive=True)\n",
    "# # for xml_file in xml_files:\n",
    "# #     convert_xml_to_yolo(xml_file)\n",
    "\n",
    "# # 1ë‹¨ê³„ ë°ì´í„° êµ¬ì„± YAML íŒŒì¼ ìƒì„±\n",
    "# data_config_1 = {\n",
    "#     \"train\": pklot_folder,\n",
    "#     \"nc\": 2,\n",
    "#     \"names\": [\"empty\", \"occupied\"]\n",
    "# }\n",
    "\n",
    "# yaml_file_1 = \"pklot_stage1.yaml\"\n",
    "# with open(yaml_file_1, \"w\") as f:\n",
    "#     yaml.dump(data_config_1, f, default_flow_style=False)\n",
    "# print(f\"1ë‹¨ê³„ YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_file_1}\")\n",
    "\n",
    "# # YOLO ëª¨ë¸ í•™ìŠµ (1ë‹¨ê³„)\n",
    "# model = YOLO(\"yolo11n.pt\")\n",
    "# model.train(data=yaml_file_1, epochs=50, batch=16, imgsz=640)\n",
    "# model.export(format=\"pt\")  # ëª¨ë¸ ì €ì¥\n",
    "\n",
    "# # 2ï¸âƒ£ **2ë‹¨ê³„: ê°œë³„ ì£¼ì°¨ ê³µê°„ ì´ë¯¸ì§€ í•™ìŠµ (Fine-Tuning)**\n",
    "# pklotsegmented_folder = \"PKLotSegmented\"\n",
    "# create_segmented_labels(pklotsegmented_folder)\n",
    "\n",
    "# # 2ë‹¨ê³„ ë°ì´í„° êµ¬ì„± YAML íŒŒì¼ ìƒì„±\n",
    "# data_config_2 = {\n",
    "#     \"train\": pklotsegmented_folder,\n",
    "#     \"val\": pklotsegmented_folder,\n",
    "#     \"nc\": 2,\n",
    "#     \"names\": [\"empty\", \"occupied\"]\n",
    "# }\n",
    "\n",
    "# yaml_file_2 = \"pklot_stage2.yaml\"\n",
    "# with open(yaml_file_2, \"w\") as f:\n",
    "#     yaml.dump(data_config_2, f, default_flow_style=False)\n",
    "# print(f\"2ë‹¨ê³„ YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_file_2}\")\n",
    "\n",
    "# # YOLO ëª¨ë¸ Fine-Tuning (2ë‹¨ê³„)\n",
    "# fine_tuned_model = YOLO(\"yolo11n.pt\")  # 1ë‹¨ê³„ í•™ìŠµ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ Fine-Tuning\n",
    "# fine_tuned_model.train(data=yaml_file_2, epochs=10, batch=16, imgsz=640)\n",
    "# fine_tuned_model.export(format=\"pt\")  # ìµœì¢… ëª¨ë¸ ì €ì¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "# import cv2\n",
    "# import xml.etree.ElementTree as ET\n",
    "# import yaml\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# def convert_xml_to_yolo(xml_path):\n",
    "#     \"\"\"\n",
    "#     pklot í´ë” ë‚´ì˜ XML annotation íŒŒì¼ì„ ì½ì–´, ë™ì¼ í´ë”ì— YOLO í˜•ì‹ì˜ txt íŒŒì¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "#     XML íŒŒì¼ê³¼ ë™ì¼í•œ ì´ë¦„ì˜ jpg ì´ë¯¸ì§€ê°€ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "#     ê° <space> íƒœê·¸ì˜ 'occupied' ì†ì„±ì„ í´ë˜ìŠ¤ ë ˆì´ë¸”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "#     \"\"\"\n",
    "#     tree = ET.parse(xml_path)\n",
    "#     root = tree.getroot()\n",
    "    \n",
    "#     # XML íŒŒì¼ê³¼ ë™ì¼í•œ ì´ë¦„ (í™•ì¥ìë§Œ jpg)ì¸ ì´ë¯¸ì§€ ê²½ë¡œ ìƒì„±\n",
    "#     base = os.path.splitext(os.path.basename(xml_path))[0]\n",
    "#     img_path = os.path.join(os.path.dirname(xml_path), base + \".jpg\")\n",
    "#     if not os.path.exists(img_path):\n",
    "#         print(f\"ì´ë¯¸ì§€ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {img_path}\")\n",
    "#         return\n",
    "    \n",
    "#     image = cv2.imread(img_path)\n",
    "#     if image is None:\n",
    "#         print(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_path}\")\n",
    "#         return\n",
    "#     img_h, img_w = image.shape[:2]\n",
    "    \n",
    "#     yolo_lines = []\n",
    "#     for space in root.findall('space'):\n",
    "#         # 'occupied' ì†ì„±ì„ ì½ì–´ í´ë˜ìŠ¤ ë ˆì´ë¸”ë¡œ ì‚¬ìš© (ì˜ˆ: 0: empty, 1: occupied)\n",
    "#         occupied_str = space.get('occupied', '0')\n",
    "#         try:\n",
    "#             label = int(occupied_str)\n",
    "#         except ValueError:\n",
    "#             label = 0\n",
    "        \n",
    "#         contour = space.find('contour')\n",
    "#         if contour is None:\n",
    "#             continue\n",
    "#         xs, ys = [], []\n",
    "#         for point in contour.findall('point'):\n",
    "#             try:\n",
    "#                 x = float(point.get('x'))\n",
    "#                 y = float(point.get('y'))\n",
    "#             except (TypeError, ValueError):\n",
    "#                 continue\n",
    "#             xs.append(x)\n",
    "#             ys.append(y)\n",
    "#         if not xs or not ys:\n",
    "#             continue\n",
    "        \n",
    "#         xmin, xmax = min(xs), max(xs)\n",
    "#         ymin, ymax = min(ys), max(ys)\n",
    "#         bbox_w = xmax - xmin\n",
    "#         bbox_h = ymax - ymin\n",
    "#         center_x = xmin + bbox_w / 2\n",
    "#         center_y = ymin + bbox_h / 2\n",
    "        \n",
    "#         # ì •ê·œí™”ëœ ì¢Œí‘œ (YOLO í˜•ì‹: [í´ë˜ìŠ¤, center_x, center_y, width, height])\n",
    "#         center_x_norm = center_x / img_w\n",
    "#         center_y_norm = center_y / img_h\n",
    "#         width_norm = bbox_w / img_w\n",
    "#         height_norm = bbox_h / img_h\n",
    "        \n",
    "#         line = f\"{label} {center_x_norm:.6f} {center_y_norm:.6f} {width_norm:.6f} {height_norm:.6f}\"\n",
    "#         yolo_lines.append(line)\n",
    "    \n",
    "#     txt_path = os.path.join(os.path.dirname(xml_path), base + \".txt\")\n",
    "#     with open(txt_path, 'w') as f:\n",
    "#         for line in yolo_lines:\n",
    "#             f.write(line + \"\\n\")\n",
    "#     print(f\"ìƒì„±ëœ YOLO annotation íŒŒì¼: {txt_path}\")\n",
    "\n",
    "# def create_segmented_labels(folder_path):\n",
    "#     \"\"\"\n",
    "#     pklotsegmented í´ë” ë‚´ì˜ ëª¨ë“  jpg ì´ë¯¸ì§€ì— ëŒ€í•´, \n",
    "#     ìƒìœ„ í´ë” ì´ë¦„(Empty ë˜ëŠ” Occupied)ì— ë”°ë¼ annotation íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \n",
    "#     - ìƒìœ„ í´ë”ê°€ 'occupied'(ëŒ€ì†Œë¬¸ì ë¬´ê´€)ì´ë©´ í´ë˜ìŠ¤ 1 (occupied)\n",
    "#     - ê·¸ ì™¸ëŠ” í´ë˜ìŠ¤ 0 (empty)\n",
    "    \n",
    "#     annotationì€ ì´ë¯¸ì§€ ì „ì²´ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ë¯€ë¡œ, ì •ê·œí™”ëœ bounding boxëŠ”\n",
    "#     center=(0.5, 0.5), width=1, height=1 ë¡œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "#     \"\"\"\n",
    "#     image_files = glob.glob(os.path.join(folder_path, \"**/**/**/**/*.jpg\"), recursive=True)\n",
    "#     for img_file in image_files:\n",
    "#         parent_folder = os.path.basename(os.path.dirname(img_file))\n",
    "#         if parent_folder.lower() == \"occupied\":\n",
    "#             label = 1\n",
    "#         else:\n",
    "#             label = 0\n",
    "        \n",
    "#         annotation_line = f\"{label} 0.500000 0.500000 1.000000 1.000000\"\n",
    "#         txt_file = os.path.splitext(img_file)[0] + \".txt\"\n",
    "#         if not os.path.exists(txt_file):\n",
    "#             with open(txt_file, 'w') as f:\n",
    "#                 f.write(annotation_line + \"\\n\")\n",
    "#             print(f\"ìƒì„±ëœ segmented annotation íŒŒì¼: {txt_file}\")\n",
    "\n",
    "# # 1. pklot í´ë” ë‚´ì˜ ëª¨ë“  XML íŒŒì¼ì„ glob íŒ¨í„´ìœ¼ë¡œ ì°¾ì•„ YOLO annotationìœ¼ë¡œ ë³€í™˜ (í•™ìŠµ ë°ì´í„°)\n",
    "# xml_files = glob.glob(\"PKLotSegmented/**/**/**/*.xml\", recursive=True)\n",
    "# for xml_file in xml_files:\n",
    "#     convert_xml_to_yolo(xml_file)\n",
    "\n",
    "# # 2. pklotsegmented í´ë” ë‚´ì˜ ì´ë¯¸ì§€ì— ëŒ€í•´, ìƒìœ„ í´ë”(Empty/Occupied)ì— ë”°ë¼ annotation ìƒì„± (ê²€ì¦ ë°ì´í„°)\n",
    "# #    ì—¬ê¸°ì„œëŠ” í•˜ìœ„ í´ë” êµ¬ì¡°ì— ê´€ê³„ì—†ì´ í´ë” ë‚´ ëª¨ë“  jpg ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "# create_segmented_labels(\"PKLot\")\n",
    "\n",
    "# # 3. ë°ì´í„° êµ¬ì„± YAML íŒŒì¼ ìƒì„±\n",
    "# #    í•™ìŠµ ë°ì´í„°: pklot í´ë”, ê²€ì¦ ë°ì´í„°: pklotsegmented í´ë”\n",
    "# data_config = {\n",
    "#     \"train\": \"PKLotSegmented\",\n",
    "#     \"val\": \"PKLot\",\n",
    "#     \"nc\": 2,  # ë‘ í´ë˜ìŠ¤: 0 (empty), 1 (occupied)\n",
    "#     \"names\": [\"empty\", \"occupied\"]\n",
    "# }\n",
    "\n",
    "# yaml_file = \"pklot.yaml\"\n",
    "# # with open(yaml_file, \"w\") as f:\n",
    "# #     yaml.dump(data_config, f, default_flow_style=False)\n",
    "# # print(f\"ë°ì´í„° êµ¬ì„± YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {yaml_file}\")\n",
    "\n",
    "# # 4. YOLO11n ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
    "# model = YOLO(\"yolo11n.pt\")\n",
    "# model.train(data = yaml_file, epochs=5, batch=8, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# ğŸš— í´ë˜ìŠ¤ ë§¤í•‘\n",
    "class_mapping = {\n",
    "    \"ìŠ¹ìš©/ìŠ¹í•©\": 0,\n",
    "    \"ë²„ìŠ¤\": 1,\n",
    "    \"í™”ë¬¼/ê¸°íƒ€\": 2,\n",
    "    \"ì´ë¥œì°¨\": 3,\n",
    "    \"ìì „ê±°\": 4\n",
    "}\n",
    "\n",
    "def convert_xml_to_yolo(xml_path, output_dir):\n",
    "    \"\"\"\n",
    "    XMLì„ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜.\n",
    "    - image íƒœê·¸ ë³„ë¡œ ê°œë³„ txt íŒŒì¼ì„ ìƒì„±\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # XML íŒŒì¼ëª…ì—ì„œ ê³µí†µ ì´ë¦„ ì¶”ì¶œ \n",
    "    base_name = os.path.splitext(os.path.basename(xml_path))[0]\n",
    "\n",
    "    for image in root.findall(\"image\"):\n",
    "        # ê° ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ XMLì—ì„œ ì¶”ì¶œ\n",
    "        img_id = int(image.get(\"id\"))  \n",
    "        img_name = f\"{base_name}_{img_id:03d}.jpg\"  \n",
    "\n",
    "        img_width = int(image.get(\"width\"))\n",
    "        img_height = int(image.get(\"height\"))\n",
    "\n",
    "        yolo_annotations = []\n",
    "\n",
    "        for box in image.findall(\"box\"):\n",
    "            class_name = box.get(\"label\")\n",
    "            if class_name not in class_mapping:\n",
    "                continue  # ë§¤í•‘ì— ì—†ëŠ” í´ë˜ìŠ¤ëŠ” ë¬´ì‹œ\n",
    "\n",
    "            class_id = class_mapping[class_name]\n",
    "            xtl = float(box.get(\"xtl\"))\n",
    "            ytl = float(box.get(\"ytl\"))\n",
    "            xbr = float(box.get(\"xbr\"))\n",
    "            ybr = float(box.get(\"ybr\"))\n",
    "\n",
    "            # YOLO í¬ë§· ì¢Œí‘œ ë³€í™˜\n",
    "            x_center = ((xtl + xbr) / 2) / img_width\n",
    "            y_center = ((ytl + ybr) / 2) / img_height\n",
    "            bbox_width = (xbr - xtl) / img_width\n",
    "            bbox_height = (ybr - ytl) / img_height\n",
    "\n",
    "            yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\")\n",
    "\n",
    "        # YOLO í¬ë§· TXT ì €ì¥\n",
    "        output_txt_path = os.path.join(output_dir, f\"{os.path.splitext(img_name)[0]}.txt\")\n",
    "        if yolo_annotations:\n",
    "            with open(output_txt_path, \"w\") as f:\n",
    "                f.write(\"\\n\".join(yolo_annotations))\n",
    "            print(f\"âœ… ë³€í™˜ ì™„ë£Œ: {output_txt_path}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ {img_name}: ê°ì²´ ì—†ìŒ, ë³€í™˜ ìƒëµ\")\n",
    "\n",
    "def process_all_xml(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    input_dir ë‚´ ëª¨ë“  XML íŒŒì¼ì„ YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    xml_files = [f for f in os.listdir(input_dir) if f.endswith(\".xml\")]\n",
    "    if not xml_files:\n",
    "        print(\"âŒ ë³€í™˜í•  XML íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return\n",
    "\n",
    "    for xml_file in xml_files:\n",
    "        xml_path = os.path.join(input_dir, xml_file)\n",
    "        convert_xml_to_yolo(xml_path, output_dir)\n",
    "\n",
    "# ì‹¤í–‰ ì˜ˆì œ (ëª¨ë“  XML ë³€í™˜)\n",
    "xml_input_folder = \"validation/labels\"\n",
    "output_directory = \"validation/labels_yolo\"\n",
    "\n",
    "process_all_xml(xml_input_folder, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# YOLO í•™ìŠµì„ ìœ„í•œ YAML íŒŒì¼ ìƒì„± í•¨ìˆ˜\n",
    "def create_yaml_file(output_path, class_mapping):\n",
    "    yaml_data = {\n",
    "        \"path\": \"data\",  # ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ\n",
    "        \"train\": \"train/images\",  # í•™ìŠµ ë°ì´í„° ê²½ë¡œ\n",
    "        \"val\": \"validation/images\",  # ê²€ì¦ ë°ì´í„° ê²½ë¡œ\n",
    "        \"nc\": len(class_mapping),  # í´ë˜ìŠ¤ ê°œìˆ˜ (ìë™ ì„¤ì •)\n",
    "        \"names\": list(class_mapping.keys())  # í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
    "    }\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        yaml.dump(yaml_data, f, default_flow_style=False, allow_unicode=True)\n",
    "\n",
    "    print(f\"âœ… YAML íŒŒì¼ ìƒì„± ì™„ë£Œ: {output_path}\")\n",
    "\n",
    "# YAML íŒŒì¼ ìƒì„± ì‹¤í–‰\n",
    "yaml_output_path = \"car.yaml\"\n",
    "create_yaml_file(yaml_output_path, class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. ì‚¬ì „í•™ìŠµëœ YOLO11x ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = YOLO(\"yolo11x.pt\")  # YOLO11x ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‚¬ìš©\n",
    "\n",
    "# 2. í•™ìŠµ ì‹¤í–‰\n",
    "model.train(\n",
    "    data=\"data.yaml\",  # í•™ìŠµ ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼\n",
    "    epochs=100,  # ì¶”ê°€ í•™ìŠµ ì§„í–‰\n",
    "    batch=16,  # ê°€ëŠ¥í•˜ë©´ 32ë¡œ ë³€ê²½\n",
    "    imgsz=640,\n",
    "    workers=4,\n",
    "    patience = 15,\n",
    "    device=\"cuda:1\",\n",
    "    lr0=0.005,  # í•™ìŠµë¥  ê°ì†Œ ì ìš©\n",
    "    lrf=0.0001,  # ìµœì¢… í•™ìŠµë¥  ì¡°ì •\n",
    ")\n",
    "\n",
    "# 3. ê²€ì¦ ì‹¤í–‰ (Validation)\n",
    "metrics = model.val()\n",
    "print(\"ğŸ“Š ê²€ì¦ ê²°ê³¼:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3000\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# 1. ì‚¬ì „í•™ìŠµëœ YOLO11x ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = YOLO(\"yolo11x.pt\")  # YOLO11x ì‚¬ì „í•™ìŠµ ëª¨ë¸ ì‚¬ìš©\n",
    "\n",
    "# 2. í•™ìŠµ ì‹¤í–‰\n",
    "model.train(\n",
    "    data=\"data3000/data3000.yaml\",  # í•™ìŠµ ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼\n",
    "    epochs=100,  # ì¶”ê°€ í•™ìŠµ ì§„í–‰\n",
    "    batch=16,  # ê°€ëŠ¥í•˜ë©´ 32ë¡œ ë³€ê²½\n",
    "    imgsz=640,\n",
    "    workers=4,\n",
    "    patience = 15,\n",
    "    device=\"cuda:1\",\n",
    "    lr0=0.005,  # í•™ìŠµë¥  ê°ì†Œ ì ìš©\n",
    "    lrf=0.0001,  # ìµœì¢… í•™ìŠµë¥  ì¡°ì •\n",
    ")\n",
    "\n",
    "# 3. ê²€ì¦ ì‹¤í–‰ (Validation)\n",
    "metrics = model.val()\n",
    "print(\"ğŸ“Š ê²€ì¦ ê²°ê³¼:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"runs/detect/train38/weights/best.pt\")\n",
    "\n",
    "results = model.predict(\n",
    "    \"for_test.jpg\",\n",
    "    save=False,\n",
    "    imgsz=1280,\n",
    "    conf=0.5,\n",
    "    device=\"cuda:1\",\n",
    ")\n",
    "for r in results:\n",
    "    print(r.boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    boxes = r.boxes.xyxy\n",
    "    \n",
    "    for box in boxes:\n",
    "        print(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    image_path = r.path # í˜„ì¬ ì´ë¯¸ì§€ì˜ path\n",
    "    boxes = r.boxes.xyxy # í˜„ì¬ ì´ë¯¸ì§€ì˜ bboxì˜ xyì¢Œí‘œê°’ë“¤\n",
    "    cls = r.boxes.cls # í˜„ì¬ ì´ë¯¸ì§€ì˜ bboxì˜ classë“¤\n",
    "    conf = r.boxes.conf # í˜„ì¬ ì´ë¯¸ì§€ì˜ bboxì˜ confê°’\n",
    "    cls_dict = r.names # ì§€ê¸ˆ ì˜ˆì œëŠ” {0: 'joint', 1: 'side'}\n",
    "    \n",
    "    # boxes, cls, conf ê°œìˆ˜ëŠ” ê°™ê¸° ë•Œë¬¸ì— zipìœ¼ë¡œ í•œë²ˆ ë¬¶ì–´ì¤€ë‹¤\n",
    "    for box, cls_number, conf in zip(boxes, cls, conf):\n",
    "        conf_number = float(conf.item())\n",
    "        cls_number_int = int(cls_number.item())\n",
    "        cls_name = cls_dict[cls_number_int]\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1_int = int(x1.item())\n",
    "        y1_int = int(y1.item())\n",
    "        x2_int = int(x2.item())\n",
    "        y2_int = int(y2.item())\n",
    "        print(x1_int, y1_int, x2_int, y2_int, cls_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    image_path = r.path # í˜„ì¬ ì´ë¯¸ì§€ì˜ path\n",
    "    boxes = r.boxes.xyxy # í˜„ì¬ ì´ë¯¸ì§€ì˜ bboxì˜ xyì¢Œí‘œê°’ë“¤\n",
    "    cls = r.boxes.cls # í˜„ì¬ ì´ë¯¸ì§€ì˜ bboxì˜ classë“¤\n",
    "    conf = r.boxes.conf # í˜„ì¬ ì´ë¯¸ì§€ì˜ bboxì˜ confê°’\n",
    "    cls_dict = r.names # ì§€ê¸ˆ ì˜ˆì œëŠ” {0: 'joint', 1: 'side'}\n",
    "    \n",
    "    import cv2\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, c = image.shape\n",
    "\n",
    "    image = cv2.resize(image, (640, 640)) # ì¶œë ¥í•  ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ ì¡°ì •\n",
    "\n",
    "    for box, cls_number, conf in zip(boxes, cls, conf):\n",
    "        conf_number = float(conf.item())\n",
    "        cls_number_int = int(cls_number.item())\n",
    "        cls_name = cls_dict[cls_number_int]\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1_int = int(x1.item())\n",
    "        y1_int = int(y1.item())\n",
    "        x2_int = int(x2.item())\n",
    "        y2_int = int(y2.item())\n",
    "        print(x1_int, y1_int, x2_int, y2_int, cls_name)\n",
    "\n",
    "        # ì¶œë ¥í•  ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ì¡°ì •í–ˆê¸° ë•Œë¬¸ì— ì¢Œí‘œê°’ë„ ê°™ì´ ì¡°ì • í•œë‹¤\n",
    "        scale_factor_x = 640 / w\n",
    "        scale_factor_y = 640 / h\n",
    "        x1_scale = int(x1_int * scale_factor_x)\n",
    "        y1_scale = int(y1_int * scale_factor_y)\n",
    "        x2_scale = int(x2_int * scale_factor_x)\n",
    "        y2_scale = int(y2_int * scale_factor_y)\n",
    "\n",
    "        image = cv2.rectangle(\n",
    "            image, (x1_scale, y1_scale), (x2_scale, y2_scale), (0, 225, 0), 6\n",
    "        )\n",
    "\n",
    "    cv2.imwrite(\"pred.jpg\", image) # ì´ë¯¸ì§€ ì €ì¥\n",
    "    cv2.imshow(\"Test\", image)\n",
    "    cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3team5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
